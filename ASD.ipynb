{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Analysis Using Spark Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##A. Blockchain Data Analysis – Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(\"BlockchainAnalysis\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "blockchain_data = '/project1/blockchain_data.csv'\n",
    "data = sc.textFile(blockchain_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1. How many total blocks are there in your dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Blocks: 1003\n"
     ]
    }
   ],
   "source": [
    "total_blocks = data.count()\n",
    "print \"Total Blocks:\", total_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2. What is the largest block height among the blocks in your dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Largest Block Height:', 820527)\n"
     ]
    }
   ],
   "source": [
    "block_heights = data.filter(lambda line: \"height\" not in line).map(lambda line: int(line.split(\",\")[1].strip()))\n",
    "largest_block_height = block_heights.max()\n",
    "print(\"Largest Block Height:\", largest_block_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3. What is the date and time for that block?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Date and Time for the Largest Block:', u'2023-12-10', u'1702187812')\n"
     ]
    }
   ],
   "source": [
    "largest_block_info = data.filter(lambda line: \"height\" not in line).\\\n",
    "    filter(lambda line: int(line.split(\",\")[1].strip()) == largest_block_height).collect()[0]\n",
    "date, time = largest_block_info.split(\",\")[0].strip(), largest_block_info.split(\",\")[3].strip()\n",
    "print(\"Date and Time for the Largest Block:\", date, time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###4. What is the highest number of transactions in your blocks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "highest_transactions = 0\n",
    "\n",
    "for block in data:\n",
    "    num_transactions = block.get('n_tx', 0)\n",
    "    if num_transactions > highest_transactions:\n",
    "        highest_transactions = num_transactions\n",
    "\n",
    "print(\"Highest number of transactions in a block:\", highest_transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##B. Stock Market Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_data = '/project1/mydata/stock-data-.*'\n",
    "data = sc.textFile(stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsed_data = data.map(lambda line: line.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'AAPL, 2023-10-23 19:06:00, 172.8950, 172.9200, 172.9800, 172.8100, 10',\n",
       " u'MSFT, 2023-10-23 19:06:00, 330.1400, 330.2900, 330.2900, 330.1300, 32',\n",
       " u'GOOGL, 2023-10-23 19:06:00, 137.2000, 137.2400, 137.2800, 137.2000, 155',\n",
       " u'TSLA, 2023-10-23 19:06:00, 213.3500, 213.2500, 213.3500, 213.2500, 1886',\n",
       " u'AMZN, 2023-10-23 19:06:00, 127.0000, 127.0300, 127.0300, 126.9600, 198',\n",
       " u'AAPL, 2023-10-23 19:06:00, 172.8950, 172.9200, 172.9800, 172.8100, 10',\n",
       " u'MSFT, 2023-10-23 19:06:00, 330.1400, 330.2900, 330.2900, 330.1300, 32',\n",
       " u'GOOGL, 2023-10-23 19:06:00, 137.2000, 137.2400, 137.2800, 137.2000, 155',\n",
       " u'TSLA, 2023-10-23 19:06:00, 213.3500, 213.2500, 213.3500, 213.2500, 1886',\n",
       " u'AMZN, 2023-10-23 19:06:00, 127.0000, 127.0300, 127.0300, 126.9600, 198',\n",
       " u'AAPL, 2023-10-23 19:06:00, 172.8950, 172.9200, 172.9800, 172.8100, 10',\n",
       " u'MSFT, 2023-10-23 19:06:00, 330.1400, 330.2900, 330.2900, 330.1300, 32',\n",
       " u'GOOGL, 2023-10-23 19:06:00, 137.2000, 137.2400, 137.2800, 137.2000, 155',\n",
       " u'TSLA, 2023-10-23 19:06:00, 213.3500, 213.2500, 213.3500, 213.2500, 1886',\n",
       " u'AMZN, 2023-10-23 19:06:00, 127.0000, 127.0300, 127.0300, 126.9600, 198',\n",
       " u'AAPL, 2023-10-23 19:06:00, 172.8950, 172.9200, 172.9800, 172.8100, 10',\n",
       " u'MSFT, 2023-10-23 19:06:00, 330.1400, 330.2900, 330.2900, 330.1300, 32',\n",
       " u'GOOGL, 2023-10-23 19:06:00, 137.2000, 137.2400, 137.2800, 137.2000, 155',\n",
       " u'TSLA, 2023-10-23 19:06:00, 213.3500, 213.2500, 213.3500, 213.2500, 1886',\n",
       " u'AMZN, 2023-10-23 19:06:00, 127.0000, 127.0300, 127.0300, 126.9600, 198',\n",
       " u'AAPL, 2023-10-24 19:21:00, 173.0100, 172.9100, 173.0100, 172.9100, 154',\n",
       " u'GOOGL, 2023-10-24 19:21:00, 130.0700,130.0000, 130.0800,129.9900, 1548',\n",
       " u'TSLA, 2023-10-24 19:21:00, 216.0150, 216.0300, 216.0500, 216.0000, 465',\n",
       " u'AMZN, 2023-10-24 19:21:00, 126.3800, 126.4700, 126.6500, 126.3600, 614',\n",
       " u'AAPL, 2023-10-24 19:21:00, 173.0100, 172.9100, 173.0100, 172.9100, 154',\n",
       " u'MSFT, 2023-10-24 19:21:00, 344.3000, 344.0000, 344.3700, 343.5100, 5208',\n",
       " u'GOOGL, 2023-10-24 19:21:00, 130.0700, 130.0000, 130.0800, 129.9900, 1548',\n",
       " u'TSLA, 2023-10-24 19:21:00, 216.0150, 216.0300, 216.0500, 216.0000, 465',\n",
       " u'AMZN, 2023-10-24 19:21:00, 126.3800, 126.4700, 126.6500, 126.3600, 614',\n",
       " u'AAPL, 2023-10-24 19:21:00, 173.0100, 172.9100, 173.0100, 172.9100, 154',\n",
       " u'MSFT, 2023-10-24 19:21:00, 344.3000, 344.0000, 344.3700, 343.5100, 5208',\n",
       " u'GOOGL, 2023-10-24 19:21:00, 130.0700, 130.0000, 130.0800, 129.9900, 1548',\n",
       " u'TSLA, 2023-10-24 19:21:00, 216.0150, 216.0300, 216.0500, 216.0000, 465',\n",
       " u'AMZN, 2023-10-24 19:21:00, 126.3800, 126.4700, 126.6500, 126.3600, 614',\n",
       " u'AAPL, 2023-10-24 19:21:00, 173.0100, 172.9100, 173.0100, 172.9100, 154',\n",
       " u'MSFT, 2023-10-24 19:21:00, 344.3000, 344.0000, 344.3700, 343.5100,  5208',\n",
       " u'GOOGL, 2023-10-24 19:21:00, 130.0700, 130.0000, 130.0800, 129.9900, 1548',\n",
       " u'TSLA, 2023-10-24 19:21:00, 216.0150, 216.0300, 216.0500, 216.0000, 465',\n",
       " u'AMZN, 2023-10-24 19:21:00, 126.3800, 126.4700, 126.6500, 126.3600, 614',\n",
       " u'AAPL, 2023-10-24 19:21:00, 173.0100, 172.9100, 173.0100, 172.9100, 154',\n",
       " u'MSFT, 2023-10-24 19:21:00, 344.3000, 344.0000, 344.3700, 343.5100, 5208',\n",
       " u'GOOGL, 2023-10-24 19:21:00, 130.0700, 130.0000, 130.0800, 129.9900, 1548',\n",
       " u'TSLA, 2023-10-24 19:21:00, 216.0150, 216.0300, 216.0500, 216.0000, 465',\n",
       " u'AMZN, 2023-10-24 19:21:00, 126.3800, 126.4700, 126.6500, 126.3600, 614',\n",
       " u'AAPL, 2023-10-24 19:21:00, 173.0100, 172.9100, 173.0100, 172.9100, 154']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. How many records are there in the table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 45\n"
     ]
    }
   ],
   "source": [
    "record_count = parsed_data.count()\n",
    "print \"Total records: {}\".format(record_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. How many different days are there in the table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total different days: 2\n"
     ]
    }
   ],
   "source": [
    "distinct_days_count = parsed_data.map(lambda values: values[1]).distinct().count()\n",
    "print \"Total different days: {}\".format(distinct_days_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. How many records per each day are there in the table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records per day:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u' 2023-10-24 19:21:00', 25), (u' 2023-10-23 19:06:00', 20)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_per_day = parsed_data.map(lambda values: (values[1], 1)).reduceByKey(lambda x, y: x + y)\n",
    "print \"Records per day:\"\n",
    "records_per_day.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What are the symbols in the table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbols:\n",
      "[u'MSFT', u'AAPL', u'AMZN', u'TSLA', u'GOOGL']\n"
     ]
    }
   ],
   "source": [
    "symbols = parsed_data.map(lambda values: values[0]).distinct()\n",
    "print \"Symbols:\"\n",
    "print symbols.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. What is the highest price for each symbol?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest price per symbol:\n",
      "[(u'MSFT', 344.0), (u'AAPL', 172.92), (u'AMZN', 127.03), (u'TSLA', 216.03), (u'GOOGL', 137.24)]\n"
     ]
    }
   ],
   "source": [
    "highest_price_per_symbol = parsed_data.map(lambda values: (values[0], float(values[3])))\n",
    "max_prices = highest_price_per_symbol.reduceByKey(lambda x, y: max(x, y))\n",
    "print \"Highest price per symbol:\"\n",
    "print max_prices.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. What is the lowest price for each symbol?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest price per symbol:\n",
      "[(u'MSFT', 330.29), (u'AAPL', 172.98), (u'AMZN', 126.65), (u'TSLA', 213.35), (u'GOOGL', 130.08)]\n"
     ]
    }
   ],
   "source": [
    "lowest_price_per_symbol = parsed_data.map(lambda values: (values[0], float(values[4])))\n",
    "min_prices = lowest_price_per_symbol.reduceByKey(lambda x, y: min(x, y))\n",
    "print \"Lowest price per symbol:\"\n",
    "print min_prices.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. What is the average price for each symbol?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average price per symbol:\n",
      "[(u'MSFT', 337.22), (u'AAPL', 172.964), (u'AMZN', 126.65555555555557), (u'TSLA', 214.83055555555555), (u'GOOGL', 133.23888888888888)]\n"
     ]
    }
   ],
   "source": [
    "average_price_per_symbol = parsed_data.map(lambda values: (values[0], float(values[2])))\n",
    "total_prices = average_price_per_symbol.combineByKey(lambda value: (value, 1),\n",
    "                                                     lambda x, value: (x[0] + value, x[1] + 1),\n",
    "                                                     lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "average_prices = total_prices.mapValues(lambda x: x[0] / x[1])\n",
    "print \"Average price per symbol:\"\n",
    "print average_prices.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. What is the range of price for each symbol?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price range per symbol:\n",
      "[(u'MSFT', (330.14, 344.0, 330.29)), (u'AAPL', (172.895, 172.92, 172.98)), (u'AMZN', (126.38, 127.03, 126.65)), (u'TSLA', (213.35, 216.03, 213.35)), (u'GOOGL', (130.07, 137.24, 130.08))]\n"
     ]
    }
   ],
   "source": [
    "price_range_per_symbol = parsed_data.map(lambda values: (values[0], (float(values[2]), float(values[3]), float(values[4]))))\n",
    "range_per_symbol = price_range_per_symbol.reduceByKey(lambda x, y: (min(x[0], y[0]), max(x[1], y[1]), min(x[2], y[2])))\n",
    "print \"Price range per symbol:\"\n",
    "print range_per_symbol.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. What is the date on which each symbol experienced the highest price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date on which each symbol experienced the highest price:\n",
      "[(u'MSFT', (u' 2023-10-24 19:21:00', 344.0)), (u'AAPL', (u' 2023-10-23 19:06:00', 172.92)), (u'AMZN', (u' 2023-10-23 19:06:00', 127.03)), (u'TSLA', (u' 2023-10-24 19:21:00', 216.03)), (u'GOOGL', (u' 2023-10-23 19:06:00', 137.24))]\n"
     ]
    }
   ],
   "source": [
    "date_highest_price_per_symbol = parsed_data.map(lambda values: (values[0], (values[1], float(values[3]))))\n",
    "max_date_price_per_symbol = date_highest_price_per_symbol.reduceByKey(lambda x, y: max(x, y, key=lambda z: z[1]))\n",
    "print \"Date on which each symbol experienced the highest price:\"\n",
    "print max_date_price_per_symbol.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## C. Blockchain Data Analysis – Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(\"Block_data\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table_1 = '/project1/Part_C/blocks_2023_Sep_10_to_15.csv'\n",
    "table_2 = '/project1/Part_C/blocks_info_2023_Sep_10_to_15.csv'\n",
    "table_3 = '/project1/Part_C/tx_info_2023_Sep_10_to_15.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_1 = sc.textFile(table_1)\n",
    "data_2 = sc.textFile(table_2)\n",
    "data_3 = sc.textFile(table_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table1_header = data_1.first()\n",
    "table2_header = data_2.first()\n",
    "table3_header = data_3.first()\n",
    "table1_data = data_1.filter(lambda line: line != table1_header)\n",
    "table2_data = data_2.filter(lambda line: line != table2_header)\n",
    "table3_data = data_3.filter(lambda line: line != table3_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. How many total blocks are there in your blocks table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total blocks: 920\n"
     ]
    }
   ],
   "source": [
    "total_blocks = table1_data.count()\n",
    "print \"Total blocks: {}\".format(total_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What is the largest block height among the blocks in your blocks table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest block height: (u'99', 806883)\n"
     ]
    }
   ],
   "source": [
    "table1_rdd = table1_data.map(lambda line: (line.split(',')[0], int(line.split(',')[3])))\n",
    "table2_rdd = table2_data.map(lambda line: (line.split(',')[0], int(line.split(',')[9])))\n",
    "\n",
    "union_rdd = table1_rdd.union(table2_rdd)\n",
    "\n",
    "largest_block_height = union_rdd.max()\n",
    "print \"Largest block height: {}\".format(largest_block_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What is the date and time for that block?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for Block 807290: 12-09-2023 00:00\n"
     ]
    }
   ],
   "source": [
    "table1_rdd = table1_data.map(lambda line: (int(line.split(',')[3]), line.split(',')[2]))\n",
    "\n",
    "filtered_rdd = table1_rdd.filter(lambda x: x[0] == 807290)\n",
    "\n",
    "result = filtered_rdd.collect()\n",
    "\n",
    "if result:\n",
    "    print(\"Time for Block 807290: {}\".format(result[0][1]))\n",
    "else:\n",
    "    print(\"Block 807290 not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###4. What is the largest number of transactions in your blocks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest Transaction: 807118, Count: 7252\n"
     ]
    }
   ],
   "source": [
    "table3_rdd = table3_data.map(lambda line: (int(line.split(',')[15]), 1))\n",
    "\n",
    "block_index_counts = table3_rdd.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "largest_tx = block_index_counts.max(key=lambda x: x[1])\n",
    "\n",
    "print(\"Largest Transaction: {}, Count: {}\".format(largest_tx[0], largest_tx[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Step 3: Data Analysis Using Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SQLContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Blockchain Data Analysis – Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# Create a Spark context\n",
    "sc = SparkContext(\"local\", \"BlockchainAnalysis\")\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# Load the data from HDFS\n",
    "data = sc.textFile(\"/project1/blockchain_data.csv\")\n",
    "\n",
    "# Parse the CSV data into RDD\n",
    "header = data.first()\n",
    "data = data.filter(lambda line: line != header).map(lambda line: line.split(','))\n",
    "\n",
    "# Convert height to integer for comparison\n",
    "data = data.map(lambda x: (x[0], int(x[1]), x[2], int(x[3])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1. How many total blocks are there in your dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total Blocks:', 1003)\n"
     ]
    }
   ],
   "source": [
    "total_blocks = data.count()\n",
    "print(\"Total Blocks:\", total_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2. What is the largest block height among the blocks in your dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Largest Block Height:', 820527)\n"
     ]
    }
   ],
   "source": [
    "largest_block = data.max(lambda x: x[1])\n",
    "largest_block_height = largest_block[1]\n",
    "print(\"Largest Block Height:\", largest_block_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3. What is the date and time for that block?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Date and Time for the Largest Block Height:', [(u'2023-12-10', 1702187812)])\n"
     ]
    }
   ],
   "source": [
    "largest_block_info = data.filter(lambda x: x[1] == largest_block_height).map(lambda x: (x[0], x[3])).collect()\n",
    "print(\"Date and Time for the Largest Block Height:\", largest_block_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###4. What is the highest number of transactions in your blocks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Highest Number of Transactions:', (u'2023-12-10', 820527, u'000000000000000000027333dc0ccb403a30c521052e23b8cc898a64c8632f9a', 1702187812))\n"
     ]
    }
   ],
   "source": [
    "highest_transactions = data.max(lambda x: x[3])\n",
    "print(\"Highest Number of Transactions:\", highest_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##B. Stock Market Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close  High   Low    Open    Symbol Timestamp            Volume\n",
      "172.92 172.98 172.81 172.895 AAPL    2023-10-23 19:06:00 10    \n",
      "330.29 330.29 330.13 330.14  MSFT    2023-10-23 19:06:00 32    \n",
      "137.24 137.28 137.2  137.2   GOOGL   2023-10-23 19:06:00 155   \n",
      "213.25 213.35 213.25 213.35  TSLA    2023-10-23 19:06:00 1886  \n",
      "127.03 127.03 126.96 127.0   AMZN    2023-10-23 19:06:00 198   \n",
      "172.92 172.98 172.81 172.895 AAPL    2023-10-23 19:06:00 10    \n",
      "330.29 330.29 330.13 330.14  MSFT    2023-10-23 19:06:00 32    \n",
      "137.24 137.28 137.2  137.2   GOOGL   2023-10-23 19:06:00 155   \n",
      "213.25 213.35 213.25 213.35  TSLA    2023-10-23 19:06:00 1886  \n",
      "127.03 127.03 126.96 127.0   AMZN    2023-10-23 19:06:00 198   \n",
      "172.92 172.98 172.81 172.895 AAPL    2023-10-23 19:06:00 10    \n",
      "330.29 330.29 330.13 330.14  MSFT    2023-10-23 19:06:00 32    \n",
      "137.24 137.28 137.2  137.2   GOOGL   2023-10-23 19:06:00 155   \n",
      "213.25 213.35 213.25 213.35  TSLA    2023-10-23 19:06:00 1886  \n",
      "127.03 127.03 126.96 127.0   AMZN    2023-10-23 19:06:00 198   \n",
      "172.92 172.98 172.81 172.895 AAPL    2023-10-23 19:06:00 10    \n",
      "330.29 330.29 330.13 330.14  MSFT    2023-10-23 19:06:00 32    \n",
      "137.24 137.28 137.2  137.2   GOOGL   2023-10-23 19:06:00 155   \n",
      "213.25 213.35 213.25 213.35  TSLA    2023-10-23 19:06:00 1886  \n",
      "127.03 127.03 126.96 127.0   AMZN    2023-10-23 19:06:00 198   \n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row\n",
    "\n",
    "sc = SparkContext(\"local\", \"StockDataAnalysis\")\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# Assuming you have an RDD named 'your_rdd' containing the stock data\n",
    "your_rdd = sc.textFile(\"/project1/mydata/stock-data-.*\")\n",
    "\n",
    "def parse_line(line):\n",
    "    parts = line.split(',')\n",
    "    return Row(Symbol=parts[0], Timestamp=parts[1], \n",
    "               Open=float(parts[2]), Close=float(parts[3]),  # Fix the index for 'Close'\n",
    "               High=float(parts[4]), Low=float(parts[5]), \n",
    "               Volume=int(parts[6]))\n",
    "\n",
    "# Converting RDD to DataFrame\n",
    "df = sqlContext.createDataFrame(your_rdd.map(parse_line))\n",
    "\n",
    "# Registering the DataFrame as a temp table\n",
    "df.registerTempTable(\"stock_data\")\n",
    "\n",
    "result = sqlContext.sql(\"SELECT * FROM stock_data\")\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1. How many records are there in the table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Records: 45\n"
     ]
    }
   ],
   "source": [
    "count = sqlContext.sql(\"SELECT COUNT(*) as record_count FROM stock_data\").first().record_count\n",
    "print(\"Number of Records: {}\".format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. How many different days are there in the table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total different days:', 2)\n"
     ]
    }
   ],
   "source": [
    "distinct_days_count = sqlContext.sql(\"SELECT COUNT(DISTINCT `Timestamp`) FROM stock_data\").collect()[0][0]\n",
    "print(\"Total different days:\", distinct_days_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3. How many records per each day are there in the table?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp            RecordCount\n",
      " 2023-10-24 19:21:00 25         \n",
      " 2023-10-23 19:06:00 20         \n"
     ]
    }
   ],
   "source": [
    "records_per_day = sqlContext.sql(\"SELECT `Timestamp`, COUNT(*) as RecordCount FROM stock_data GROUP BY `Timestamp`\")\n",
    "records_per_day.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###4. What are the symbols in the table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol\n",
      "AAPL  \n",
      "GOOGL \n",
      "AMZN  \n",
      "MSFT  \n",
      "TSLA  \n"
     ]
    }
   ],
   "source": [
    "symbols = sqlContext.sql(\"SELECT DISTINCT `Symbol` FROM stock_data\")\n",
    "symbols.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###5. What is the highest price for each symbol?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol HighestPrice\n",
      "AAPL   173.01      \n",
      "GOOGL  137.28      \n",
      "AMZN   127.03      \n",
      "MSFT   344.37      \n",
      "TSLA   216.05      \n"
     ]
    }
   ],
   "source": [
    "highest_price_per_symbol = sqlContext.sql(\"SELECT `Symbol`, MAX(`High`) as HighestPrice FROM stock_data GROUP BY `Symbol`\")\n",
    "highest_price_per_symbol.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###6. What is the lowest price for each symbol?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol LowestPrice\n",
      "AAPL   172.81     \n",
      "GOOGL  129.99     \n",
      "AMZN   126.36     \n",
      "MSFT   330.13     \n",
      "TSLA   213.25     \n"
     ]
    }
   ],
   "source": [
    "lowest_price_per_symbol = sqlContext.sql(\"SELECT `Symbol`, MIN(`Low`) as LowestPrice FROM stock_data GROUP BY `Symbol`\")\n",
    "lowest_price_per_symbol.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###7. What is the average price for each symbol?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol AveragePrice      \n",
      "AAPL   172.914           \n",
      "GOOGL  133.21777777777777\n",
      "AMZN   126.7188888888889 \n",
      "MSFT   337.145           \n",
      "TSLA   214.79444444444445\n"
     ]
    }
   ],
   "source": [
    "average_price_per_symbol = sqlContext.sql(\"SELECT `Symbol`, AVG(`Close`) as AveragePrice FROM stock_data GROUP BY `Symbol`\")\n",
    "average_price_per_symbol.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###8. What is the range of price for each symbol?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol PriceRange         \n",
      "AAPL   0.19999999999998863\n",
      "GOOGL  7.289999999999992  \n",
      "AMZN   0.6700000000000017 \n",
      "MSFT   14.240000000000009 \n",
      "TSLA   2.8000000000000114 \n"
     ]
    }
   ],
   "source": [
    "price_range_per_symbol = sqlContext.sql(\"SELECT `Symbol`, MAX(`High`) - MIN(`Low`) as PriceRange FROM stock_data GROUP BY `Symbol`\")\n",
    "price_range_per_symbol.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###9. What is the date on which each symbol experienced the highest price?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol highest_date         highest_price\n",
      "AAPL    2023-10-24 19:21:00 173.01       \n",
      "GOOGL   2023-10-24 19:21:00 137.28       \n",
      "AMZN    2023-10-24 19:21:00 127.03       \n",
      "MSFT    2023-10-24 19:21:00 344.37       \n",
      "TSLA    2023-10-24 19:21:00 216.05       \n"
     ]
    }
   ],
   "source": [
    "date_highest_price = sqlContext.sql(\"SELECT `Symbol`, MAX(`Timestamp`) AS highest_date, MAX(`High`) AS highest_price FROM stock_data GROUP BY`Symbol`\")\n",
    "date_highest_price.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Blockchain Data Analysis – Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sc = SparkContext(\"local\", \"Block_info\")\n",
    "sqlCtx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blocks = sqlCtx.load(source=\"jdbc\", \n",
    "                         url=\"jdbc:mysql://localhost/project1?user=training&password=training\", \n",
    "                         dbtable=\"table_1\")\n",
    "\n",
    "blocks_info = sqlCtx.load(source=\"jdbc\", \n",
    "                         url=\"jdbc:mysql://localhost/project1?user=training&password=training\", \n",
    "                         dbtable=\"table_2\")\n",
    "\n",
    "tx_info = sqlCtx.load(source=\"jdbc\", \n",
    "                         url=\"jdbc:mysql://localhost/project1?user=training&password=training\", \n",
    "                         dbtable=\"table_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blocks.registerTempTable(\"blocks\")\n",
    "blocks_info.registerTempTable(\"blocks_info\")\n",
    "tx_info.registerTempTable(\"tx_info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1. How many total blocks are there in your blocks table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_blocks\n",
      "921         \n"
     ]
    }
   ],
   "source": [
    "total_blocks = sqlCtx.sql(\"SELECT COUNT(*) as total_blocks FROM blocks\")\n",
    "total_blocks.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2. What is the largest block height among the blocks in your blocks table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_block_height\n",
      "807290          \n"
     ]
    }
   ],
   "source": [
    "max_block_height = sqlCtx.sql(\"SELECT MAX(height) as max_block_height FROM blocks_info\")\n",
    "max_block_height.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3. What is the date and time for that block?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_time       \n",
      "12-09-2023 00:00\n"
     ]
    }
   ],
   "source": [
    "date_time_for_specific_block = sqlCtx.sql(\"\"\"\n",
    "    SELECT time as date_time\n",
    "    FROM blocks\n",
    "    WHERE block_index = 807290\n",
    "\"\"\")\n",
    "\n",
    "date_time_for_specific_block.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###4. What is the largest number of transactions in your blocks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Largest number of transactions in a block:', 7252)\n"
     ]
    }
   ],
   "source": [
    "lrgst_number_transactions = tx_info.groupBy(\"block_index\").count().agg({\"count\": \"max\"}).collect()[0][0]\n",
    "print(\"Largest number of transactions in a block:\", lrgst_number_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
